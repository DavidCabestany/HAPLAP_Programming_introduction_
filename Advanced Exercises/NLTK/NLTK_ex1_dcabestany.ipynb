{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 1\n",
    "\n",
    "texto = 'hola me llamo ralph y soy especial'\n",
    "\n",
    "def richness(text):\n",
    "    tWords = len(text)\n",
    "    uWords = len(set(text))\n",
    "    \n",
    "    richness = tWords/uWords\n",
    "    \n",
    "    return round(richness, 2)\n",
    "\n",
    "\n",
    "richness(texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exercise 2\n",
    "books = text1,text2,text3,text4,text5,text6,text7,text8,text9\n",
    "\n",
    "LBooks = []\n",
    "    \n",
    "def exercise2():\n",
    "   \n",
    "    marks = ['.', '.\"', ',',',\"', ';',';\"', ':',':\"', \\\n",
    "            '?','?\"', '!','!\"', '\"', '-','-\"', '--','--\"',\\\n",
    "            '\\'','\"\\'', '/']\n",
    "    SW_en = set(stopwords.words('english'))\n",
    "    text_rec = nltk.FreqDist([word.lower() for word in text1 if word not in SW_en and word not in marks])\n",
    "    return text_rec.most_common(30)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exercise2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SW_en = set(stopwords.words('english'))\n",
    "books = text1,text2,text3,text4,text5,text6,text7,text8,text9\n",
    "text_rec = nltk.FreqDist([word.lower() for word in text1 if word not in SW_en for book in books]).most_common(30)\n",
    "\n",
    "def freq_iter(texts):\n",
    "    freqs = []\n",
    "    marks = ['.', '.\"', ',',',\"', ';',';\"', ':',':\"', \\\n",
    "            '?','?\"', '!','!\"', '\"', '-','-\"', '--','--\"',\\\n",
    "            '\\'','\"\\'', '/']\n",
    "    for text in texts:\n",
    "        freqs.append(\"Those are the 30 most common words of\" + str(text) + ':')\n",
    "        freqs.append(nltk.FreqDist([word.lower() for word in text1 if word not in SW_en and word not in marks]).most_common(30))\n",
    "        freqs.append(\"\\n\")\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "freq_iter(books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nltk_pkg():\n",
    "    book = [text1, text2, text3, text4, \\\n",
    "            text5, text6, text7, text8, text9]\n",
    "    rText = []\n",
    "    rList = []\n",
    "    clean = []\n",
    "    SW_en = set(stopwords.words('english'))\n",
    "    marks = ['.', '.\"', ',',',\"', ';',';\"', ':',':\"', \\\n",
    "                '?','?\"', '!','!\"', '\"', '-','-\"', '--','--\"',\\\n",
    "                '\\'','\"\\'', '/']\n",
    "    def common_trh(text):\n",
    "        for word in text:\n",
    "            if word not in SW_en and word not in marks:\n",
    "                clean.append(word)\n",
    "        fdist = FreqDist(clean)\n",
    "        rList = fdist.most_common(30)\n",
    "        return rList\n",
    "    for text in book:\n",
    "        rText.append(text)\n",
    "        #rText.append(\"\\n\")\n",
    "        rText.append(common_trh(text))\n",
    "        #rText.append(\"\\n\")\n",
    "    return rText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "nltk_pkg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gutenberg():\n",
    "\n",
    "    url = \"http://www.gutenberg.org/files/2554/2554-0.txt\"\n",
    "    response = request.urlopen(url)\n",
    "    raw = response.read().decode('utf8')\n",
    "    tok_txt = word_tokenize(raw)\n",
    "    wn_lem = WordNetLemmatizer()\n",
    "    lem_txt = []\n",
    "\n",
    "    for word in tok_txt:\n",
    "        lem_txt.append(wn_lem.lemmatize(word))\n",
    "    \n",
    "    return lem_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "gutenberg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percentages(text, word):\n",
    "    return (text.count(word) / len(text)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_new(word):\n",
    " \n",
    "    raw_text = [[], []]\n",
    "\n",
    "    news = [\"https://www.elperiodico.com/es/deportes/20211212/espana-gana-brasil-medira-alemania-12973552\",\\\n",
    "        \"https://www.eldiario.es/cultura/encontrar-utilidad-convierte-batalla-larga-castillo_1_8569034.html\"]\n",
    "\n",
    "    stops = set(stopwords.words('spanish'))\n",
    "\n",
    "    for i in range(len(news)):\n",
    "        print(\"URL \",  i+1, \":\")\n",
    "        url = (request.urlopen(news[i])).read().decode('utf8')\n",
    "        soup = BeautifulSoup(url, \"html.parser\")\n",
    "        for script in soup([\"script\", \"style\"]):\n",
    "            script.decompose()\n",
    "        raw = soup.get_text()\n",
    "        tok_txt = word_tokenize(raw)\n",
    "        for w in tok_txt:\n",
    "            if w not in stops:\n",
    "                raw_text[i].append(w)\n",
    "        print(word, \"= \", percentages(raw_text[i], word))\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "percent_new(\"castillo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
